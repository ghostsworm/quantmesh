# 大规模内存分配优化说明

## 概述

本文档描述了针对系统中可能大规模分配内存的地方进行的优化，以防止内存占用过大和潜在的内存泄漏。

## 已修复的问题

### 1. CSV 文件读取优化 (`backtest/data_fetcher.go`)

**问题**: 使用 `csv.ReadAll()` 一次性读取整个文件到内存，如果文件很大（例如包含数百万根K线），会导致内存占用过高。

**修复**:
- 改用流式读取（逐行读取）
- 添加最大读取数量限制（最多100万根K线）
- 使用 `io.EOF` 检测文件结束

```go
// 修复前
records, err := reader.ReadAll() // 一次性读取整个文件

// 修复后
for {
    record, err := reader.Read()
    if err == io.EOF {
        break
    }
    if len(candles) >= maxCandles {
        logger.Warn("⚠️ CSV 文件过大，只读取前 %d 根K线", maxCandles)
        break
    }
    // 处理记录
}
```

### 2. 槽位查询限制 (`position/super_position_manager.go`)

**问题**: `GetAllSlotsDetailed()` 可能返回大量槽位数据，如果槽位数量很大（例如数万个），会导致内存占用过高。

**修复**:
- 添加最大返回数量限制（最多1万个槽位）
- 超过限制时停止遍历并记录警告

```go
// 修复后
maxSlots := 10000 // 最多返回1万个槽位
spm.slots.Range(func(key, value interface{}) bool {
    if count >= maxSlots {
        logger.Warn("⚠️ [槽位查询] 槽位数量超过限制 (%d)，只返回前 %d 个", maxSlots, maxSlots)
        return false // 停止遍历
    }
    // 处理槽位
    count++
    return true
})
```

### 3. 数据库查询限制优化 (`storage/sqlite.go`)

**问题**: 多个数据库查询方法没有对返回数量进行限制，可能导致一次性返回大量数据。

**修复**: 为所有查询方法添加了 limit 限制和验证：

#### 3.1 QueryOrders - 订单查询
- 默认 limit: 100
- 最大 limit: 10,000

#### 3.2 QueryTrades - 交易查询
- 默认 limit: 100
- 最大 limit: 10,000

#### 3.3 QueryStatistics - 统计数据查询
- 添加 LIMIT 子句
- 最大返回: 10,000 条

#### 3.4 QueryReconciliationHistory - 对账历史查询
- 默认 limit: 100
- 最大 limit: 10,000

#### 3.5 GetPnLByTimeRange - 盈亏数据查询
- 添加 LIMIT 子句
- 最大返回: 1,000 个币种对（分组后的结果）

#### 3.6 GetFundingRateHistory - 资金费率历史查询
- 默认 limit: 100
- 最大 limit: 10,000

#### 3.7 GetBasisHistory - 价差历史查询
- 默认 limit: 100
- 最大 limit: 10,000

#### 3.8 QueryDailyStatisticsByExchange - 每日统计查询
- 添加 LIMIT 子句
- 最大返回: 3,650 天（10年的每日统计）

### 4. 日志查询限制 (`storage/log_storage.go`)

**已存在**: 日志查询已经有良好的限制机制：
- 默认 limit: 100
- 最大 limit: 1,000

## 限制策略总结

### 查询限制标准

| 查询类型 | 默认 Limit | 最大 Limit | 说明 |
|---------|-----------|-----------|------|
| 订单查询 | 100 | 10,000 | 单次查询最多1万条订单 |
| 交易查询 | 100 | 10,000 | 单次查询最多1万条交易 |
| 统计数据 | - | 10,000 | 最多返回1万条统计 |
| 对账历史 | 100 | 10,000 | 单次查询最多1万条对账记录 |
| 盈亏数据 | - | 1,000 | 分组后的币种对数量 |
| 资金费率历史 | 100 | 10,000 | 单次查询最多1万条费率记录 |
| 价差历史 | 100 | 10,000 | 单次查询最多1万条价差记录 |
| 每日统计 | - | 3,650 | 最多返回10年的每日统计 |
| 日志查询 | 100 | 1,000 | 单次查询最多1千条日志 |
| 风控检查历史 | 200 | 500 | 单次查询最多500条记录 |
| CSV K线数据 | - | 1,000,000 | 最多读取100万根K线 |
| 槽位查询 | - | 10,000 | 最多返回1万个槽位 |

### 限制原则

1. **默认值**: 所有查询都应该有合理的默认 limit，避免返回过多数据
2. **最大值**: 设置合理的最大值，防止恶意或错误的查询导致内存问题
3. **警告日志**: 当 limit 被限制时，记录警告日志，便于排查问题
4. **分组查询**: 对于分组后的查询（如按币种对、按日期），限制应该更严格

## 其他潜在问题

### 1. HTTP 响应体读取

**位置**: `exchange/*/client.go`, `ai/gemini_client.go`

**现状**: 使用 `io.ReadAll()` 读取 HTTP 响应体，但响应体通常不会太大（API 响应通常小于几MB）。

**建议**: 如果担心响应体过大，可以添加大小限制：
```go
// 限制响应体最大大小为 10MB
maxBodySize := 10 * 1024 * 1024
limitedReader := io.LimitReader(resp.Body, maxBodySize)
body, err := io.ReadAll(limitedReader)
```

### 2. JSON 序列化

**位置**: `web/api_config.go`, `event/center.go`, `storage/storage.go`

**现状**: 使用 `json.Marshal()` 序列化配置和事件数据，这些数据通常不会太大。

**建议**: 如果序列化的数据可能很大，可以考虑：
- 使用流式 JSON 编码器
- 限制序列化对象的大小
- 分块传输

### 3. sync.Map 遍历

**位置**: `position/super_position_manager.go`, `safety/order_cleaner.go`

**现状**: 已经为 `GetAllSlotsDetailed()` 添加了限制，其他遍历操作也应该考虑添加限制。

**建议**: 对于可能很大的 `sync.Map`，遍历时应该：
- 添加数量限制
- 使用分页或分批处理
- 考虑使用迭代器模式

## 最佳实践

### 1. 数据库查询

- ✅ 始终使用 LIMIT 子句
- ✅ 验证 limit 参数的有效性
- ✅ 设置合理的默认值和最大值
- ✅ 记录超过限制的警告日志

### 2. 文件读取

- ✅ 使用流式读取而不是一次性读取整个文件
- ✅ 添加大小或数量限制
- ✅ 处理大文件时考虑分块处理

### 3. 内存数据结构

- ✅ 限制缓存和列表的大小
- ✅ 定期清理过期或不需要的数据
- ✅ 使用分页或分批处理大量数据

### 4. API 响应

- ✅ 限制查询参数（时间范围、数量等）
- ✅ 验证和限制请求参数
- ✅ 对大数据集进行采样或聚合

## 验证方法

### 1. 内存监控

使用系统监控功能查看内存使用情况：
```bash
curl http://localhost:15173/api/system/metrics/current | jq '.memory'
```

### 2. 压力测试

- 创建大量测试数据
- 执行各种查询操作
- 观察内存使用情况

### 3. 日志检查

检查是否有警告日志：
```bash
grep "超过限制" logs/app-*.log
```

## 总结

通过以上优化，系统现在对所有可能大规模分配内存的地方都进行了限制：

1. ✅ CSV 文件读取改为流式读取
2. ✅ 槽位查询添加了数量限制
3. ✅ 所有数据库查询都添加了 limit 限制和验证
4. ✅ 设置了合理的默认值和最大值
5. ✅ 超过限制时记录警告日志

这些优化确保了系统在长期运行过程中不会因为大规模内存分配而导致内存问题。
